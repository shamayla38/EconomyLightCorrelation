# Night-Time Light and Economic Growth Correlation
## Overview

This project explores the relationship between Night-Time Light (NTL) intensity, captured via satellite imagery, and economic indicators such as GDP. It incorporates the most recent and comprehensive data available to conduct a temporal analysis spanning multiple decades. The study emphasizes the role of NTL as a robust proxy for economic activity, particularly in regions with unreliable or unavailable conventional economic data. Both R and Python were used in this analysis. 

## Data Overview
### Input Data

#### Raw Data:

Source: Night-time light data in TIFF format (e.g., harmonized VIIRS NTL data).
Location: data/raw_data/ (not included in the repository due to size). Instructions are located in the folder to download the raw files.

Intermediate Data:

#### Year-wise Data:

Generated by extracting and aggregating NTL data with country-level shapefiles.
Location: data/raw_data/04-extracted (not included in the repository due to size). Instructions are located in the folder to extract the data. 

#### Aggregated Data:

Final dataset combining all years, aggregated by country and stored in an efficient Parquet and CSV format.
Location: data/analysis_data/04-anaysis

## Directory Structure
```
NTLGDPCorr/
├── data/ 
│   ├── 00-simulated_data/
│   ├── 01-raw_data/ # Contains the tif files, shapefiles, extracted data from tif files and raw world bank data.
│   ├── 02-analysis_data/ # contains all the cleaned data innvarious format. 
│   ├── 03-plotting_data/ # contains data for plotting
├── models/
├── others/
│   ├── plots/
│   ├── sketches/
│   ├── LLLM_documentation/
│   ├── datasheet/ # containes detailed information about the data
├── paper/
├── scripts/

```
## Scripts

1. 00-simulate_data.py
Purpose: Simulates a data set to test workflows, validate methodologies, and anticipate potential issues in analysis

2. 01-data_extraction.py
Purpose: Extracts pixel-level data (latitude, longitude, and DN values) from NTL TIFF files and merges it with country shapefiles.
Output: CSV files containing country-wise DN values for each year (data/01-raw_data/03-extracted).

3. 02-data_cleaning.py
Purpose: This script cleans and processes data, saving results in various formats. It aggregates data by country, computing total DN values per country per year, and saves them in the `aggregatedbycountry` folder. It concatenates these into a single CSV file in the `concatenated` folder. It standardizes and cleans inconsistent World Bank and shapefile names, saving the processed data in `worldbankdataprocessed`. Finally, it merges all datasets into the final cleaned dataset saved in the `analysis` folder.
Output: /data/02-analysis_data.

4. 03-prepareplottingdata.r
purpose: To efficiently visualise the data, data had to be carefully organised into intervals. This script allows to create a distinct data set for creating specific plots.
Output: data/03-plotting_data/plotting.parquet

5. 04-model_data.R
Purpose: This script develops models using the prepared dataset to analyze the relationship between variables (e.g., GDP, NTL, population, etc.). 
Output: models/.rds

## Steps to Reproduce:

### Prerequisites:
Ensure the following tools and packages are installed:

Python (3.8+): Required libraries: pandas, geopandas, rasterio, numpy, shapely, ggplot.

Install with: pip install pandas geopandas rasterio numpy shapely ggplot

R (3.3+): Required libraries: arrow, tidyverse, modelsummary, here, kableExtra, tinytable, sf, scales, gridExtra, grid, png, broom, GGally, patchwork.

```{r}
install.packages(c("arrow", "tidyverse", "modelsummary", "here", "kableExtra", 
                   "tinytable", "sf", "scales", "gridExtra", "grid", "png", 
                   "broom", "GGally", "patchwork"))
```


#### Process the Data:

Place raw TIFF files in data/raw_data/.
Run the scripts in the following order:
1) data_extraction.py: Extracts data from TIFF files and merges with country shapefile.
2) data_cleaning.py: Cleans and processes the year-wise data.
3) aggregate_data.py: Aggregates cleaned data into a single Parquet file.

Final Output: data/analysis_data/aggregated/final_aggregated_data.parquet.

Use model/04-model_data.R to geenrate the linear models
Use the paper/paper.qmd to generate the plots for analysis and study modle output. 

## Acknowledgments

NTL Data Source: Harmonized VIIRS Night-Time Lights data. Link: https://gee-community-catalog.org/projects/hntl/
Shapefile Source: Global country boundary shapefiles. Link: https://hub.arcgis.com/datasets/esri::world-countries-generalized/about

## LLM Usage

LLM was used for finding code syntax, fixing code for plotting. 

## Concluding Note 
To fully understand the workflow, dataset, and methodology of this project, it is essential to review the  README.md, DATA_DESCRIPTION.txt and Scripts.  Each script in the scripts/ directory is documented and corresponds to a specific step in the workflow, from data extraction to modeling. Refer to the comments in the scripts for detailed information about their functionality.By carefully reviewing these resources, you will gain a good understanding of how the data was prepared, analyzed, and used to derive the results presented in this study.











